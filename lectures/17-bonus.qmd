---
title: "Bonus lecture"
format: 
  revealjs:
    multiplex: true
    slide-number: true
    incremental: true
    touch: true
    code-overflow: wrap
execute: 
  echo: true
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = F, 
                      message = F)
options(scipen = 999)
```

## Last time

Paired-samples *t*-tests

-   aka one-sample *t*-tests on difference scores

```{r}
library(tidyverse)
```

------------------------------------------------------------------------
  
## Today
  
  -   Repeated measures
  -   Intro to text analysis
  -   Bootstrapping?
  
------------------------------------------------------------------------

## Repeated Measures 

- How does the number of trials per participant affect statistical power?
- Can more trials compensate for fewer participants?
- How do we analyze experiments with multiple trials per participant?

------------------------------------------------------------------------

## Key Concepts {.smaller}
  
- In cognitive experiments, we have:
    - Multiple participants (n)
    - Multiple trials per participant (k)
    - Two or more conditions
    - Each trial produces a measurement
    
- Multiple trials can:
    1. Improve measurement precision
    2. Reduce within-subject variability
    3. Increase reliability

------------------------------------------------------------------------

## Simulation: Effect of Trials

(Function to simulate experiment here)
```{r}
#| code-fold: true
simulate_cognitive_experiment <- function(
    n_participants = 20,    # number of participants
    n_trials = 50,         # trials per condition per participant
    true_effect = 0.5,     # mean difference between conditions
    participant_sd = 0.25,   # between-participant variability
    trial_sd = 1.0,        # within-participant (trial) variability
    seed = 123             # for reproducibility
) {
  
  set.seed(seed)
  
  # Generate participant random effects (individual differences)
  participant_effects <- rnorm(n_participants, mean = 0, sd = participant_sd)
  
  # Create a data frame with all combinations of participants and trials
  experiment_data <- expand_grid(
    participant = 1:n_participants,
    trial = 1:n_trials,
    condition = c("A", "B")
  ) %>%
    # Add participant-level random effects
    mutate(
      participant_effect = rep(participant_effects, each = n_trials * 2),
      # Add condition effect (only for condition B)
      condition_effect = if_else(condition == "B", true_effect, 0),
      # Generate trial-level noise
      trial_noise = rnorm(n(), mean = 0, sd = trial_sd),
      # Compute response time (or other DV)
      response = 0.5 + participant_effect + condition_effect + trial_noise
    ) %>%
    # Reorder columns for clarity
    select(participant, condition, trial, response)
  
  return(experiment_data)
}
```

```{r}
# Generate example data
data <- simulate_cognitive_experiment(
  n_participants = 20,
  n_trials = 100,
  true_effect = 0.5,
  participant_sd = 0.25,
  trial_sd = 1.0
)

# View first few rows
data
```

------------------------------------------------------------------------

```{r}
# Basic summary statistics
data %>%
  group_by(condition) %>%
  summarise(
    mean_rt = mean(response),
    sd_rt = sd(response),
    n_trials = n()
  )
```
------------------------------------------------------------------------

```{r}
# Participant-level summary
data %>%
  group_by(participant, condition) %>%
  summarise(
    mean_rt = mean(response),
    sd_rt = sd(response),
    n_trials = n(),
    .groups = "drop"
  ) 
```

------------------------------------------------------------------------
  
```{r}
# Calculate effect size for each participant
participant_effects <- data %>%
  group_by(participant, condition) %>%
  summarise(
    mean_rt = mean(response),
    .groups = "drop"
  ) %>%
  pivot_wider(
    names_from = condition,
    values_from = mean_rt
  ) %>%
  mutate(effect_size = B - A)

```

```{r, echo = F}
participant_effects
```


------------------------------------------------------------------------

```{r}
# Aggregating across different trial numbers
participant_effects20 <- data %>%
  filter(trial <= 20) %>% 
  group_by(participant, condition) %>%
  summarise(
    mean_rt = mean(response),
    .groups = "drop"
  ) %>%
  pivot_wider(
    names_from = condition,
    values_from = mean_rt
  ) %>%
  mutate(effect_size = B - A)
```

```{r, echo = F}
participant_effects20
```

------------------------------------------------------------------------

```{r}
t.test(participant_effects20$A, participant_effects20$B, 
       paired = TRUE)$statistic
t.test(participant_effects$A, participant_effects$B, 
       paired = TRUE)$statistic
```

------------------------------------------------------------------------
  
## Why More Trials Help {.smaller}
  
**Law of Large Numbers**

  - Individual trial measurements are noisy
  - Mean of many trials is more stable
  - Reduces measurement error

**Standard Error Formula**

  - SE = σ / √n
  - More trials → smaller SE of participant means
  - Smaller SE → More power
  
------------------------------------------------------------------------

```{r}
#| code-fold: true
participant_effects %>% 
  mutate(Trials = 100) %>% 
  full_join(
    mutate(participant_effects20, Trials = 20)
  ) %>% 
  pivot_longer(cols = c("A", "B"),
               names_to = "condition",
               values_to = "avg_response") %>% 
  ggplot(., aes(x = condition, 
                     y = avg_response, 
                     fill = as.factor(Trials))) +
  geom_boxplot() +
  labs(title = "Reduced Variability with More Trials", 
       y = "Mean Score", 
       fill = "Number of Trials") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

------------------------------------------------------------------------
  
## Practical Guidelines
  
- More trials generally help, but with diminishing returns
- Consider:
  - Participant fatigue
  - Practice effects
  - Time constraints
  - Resource limitations

------------------------------------------------------------------------
  
## Analysis Approaches {.smaller}

Summary by [Dan McNeish](../readings/mcneish_2023.pdf)
  
- **Participant-level Analysis**
  - Average trials for each participant
  - Run paired t-test on participant means
  - Simple but may lose information
- **Multilevel modeling**
  - Use all information
  - Especially useful when interested in individual differences
- **Clustered errors and GEE**
  - Don't care about individual differences
- **Fixed effects models**
  - Useful when relevant contextual factors are not measured 


------------------------------------------------------------------------
  
## Coming Soon (PSY 613)...
  
- Mixed-effects models
  - Account for trial-level variation
  - Handle missing data
  - Model individual differences
- Power analysis for repeated measures

------------------------------------------------------------------------
  
```{r}
library(lme4)
lmer(response ~ 1 + condition + (1|participant),
     data = data) %>% 
  summary()
```

------------------------------------------------------------------------
  
## Text analysis
  
Data came from a [study of parents of young children](https://journals.sagepub.com/doi/full/10.1177/25152459231160105), collected during 2020.

Parents answered the question: "How do you feel about the COVID-19 vaccine in terms of its safety and effectiveness, and what are your plans in terms of whether or not to get it?"

```{r}
# install.packages(c("textdata", "tidytext", "wordcloud"))
library(tidytext)
library(textdata)
library(wordcloud)
rapid = read_csv("https://raw.githubusercontent.com/uopsych/psy611/refs/heads/master/data/rapid_short.csv")
```

------------------------------------------------------------------------
  
### Data Preparation
  
Let's examine and clean our text data:

```{r data_prep}
#| echo: true

# Look at the structure of our data
glimpse(rapid)
```

------------------------------------------------------------------------

Cleaning text requires the use of "regular expressions." This is like a sub-dialect of coding. The website [regex101.com](https://regex101.com/) is very useful for navigating this code, but of course, AI is great too.

```{r}
# Create a clean text column
rapid_clean <- rapid %>%
  mutate(
    response = HEALTH.030,
    # Convert to lowercase
    response = tolower(response),
    # Remove punctuation
    response = str_remove_all(response, "\\?"),
    response = str_replace_all(response, "[[:punct:]]", " "),
    # Remove extra whitespace
    response = str_squish(response)
  )

head(rapid_clean$response) # show first few responses
```

------------------------------------------------------------------------

### Breaking Text into Words

::::: columns
::: {.column width="50%"}
We'll use `tidytext` to tokenize our responses:
  
```{r tokenize}
#| echo: true
#| eval: false

words_df <- rapid_clean %>%
  unnest_tokens(word, response) %>%
  # Remove stop words
  anti_join(stop_words)

# View most common words
words_df %>%
  count(word, sort = TRUE) %>%
  slice_head(n = 10) %>%
  knitr::kable()
```
:::
  
::: {.column width="50%"}
```{r ref.label="tokenize"}
#| echo: false
```
:::
:::::

  
------------------------------------------------------------------------
  
### Visualizing Common Words
  
Let's create a word cloud:

::::: columns
::: {.column width="50%"}
```{r wordcloud}
#| echo: true
#| eval: false

words_df %>%
  count(word) %>%
  with(wordcloud(word, n, 
                max.words = 50, 
                colors = brewer.pal(8, "Dark2")))
```
:::

::: {.column width="50%"}
```{r ref.label="wordcloud"}
#| echo: false
#| fig-height: 8
#| fig-width: 5
```
:::
:::::

------------------------------------------------------------------------

### Finding Themes: Bigrams {.smaller}

Let's look at word pairs to understand context better:
  
```{r bigrams}
#| echo: true
#| code-fold: true

bigrams_df <- rapid_clean %>%
  unnest_tokens(bigram, response, token = "ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>% 
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word) %>%
  filter(!is.na(word1)) %>%
  filter(!is.na(word2))

# View top bigrams
bigrams_df %>%
  unite(bigram, word1, word2, sep = " ") %>%
  count(bigram, sort = TRUE) %>%
  slice_head(n = 10) %>%
  knitr::kable()
```

------------------------------------------------------------------------
  
### Sentiment Analysis {.smaller}
  
Let's analyze the emotional content of responses:

```{r sentiment}
#| echo: true

get_sentiments("bing") %>% 
  sample_n(10)
```

------------------------------------------------------------------------
  
### Sentiment Analysis {.smaller}

```{r}
# Add sentiment scores
sentiment_df <- words_df %>%
  inner_join(get_sentiments("bing")) %>%
  count(CaregiverID, StartDate, sentiment) %>%
  pivot_wider(names_from = sentiment, 
              values_from = n, 
              values_fill = 0) %>%
  mutate(sentiment_score = positive - negative)

sentiment_df
```

------------------------------------------------------------------------

### Sentiment Analysis {.smaller}

```{r}
#| code-fold: true
# View distribution of sentiment
ggplot(sentiment_df, aes(x = sentiment_score)) +
  geom_histogram(binwidth = 1, fill = "steelblue", alpha = 0.7) +
  geom_vline(aes(xintercept = 0), linetype = "dashed") +
  labs(title = "Distribution of Sentiment Scores",
       x = "Sentiment Score (Positive - Negative)",
       y = "Count") +
  theme_minimal()
```

------------------------------------------------------------------------

### Does sentiment change over time?

```{r}
#| code-fold: true
sentiment_df %>% 
  ggplot(aes(x = StartDate)) +
  geom_smooth(aes(y = positive, color = "positive sentiment")) +
  geom_smooth(aes(y = negative, color = "negative sentiment")) +
  scale_color_manual(values = c("#1B4965", "#FF9F1C")) +
  labs(
    x = "Time (2020)",
    y = "Sentiment score"
  ) +
  theme_minimal() +
  theme(legend.position = "top")


```

------------------------------------------------------------------------

### Key Findings

-   Most common words reveal attitudes about vaccine safety and effectiveness
-   Common bigrams show personal experiences ("already got", "fully vaccinated")
-   Sentiment analysis reveals mixed but generally positive attitudes

------------------------------------------------------------------------

### Resources for Learning More

-   tidytext documentation: https://www.tidytextmining.com/
-   [Text Mining with R](https://www.tidytextmining.com/) (free online book)
-   [UPenn Library](https://guides.library.upenn.edu/penntdm/r)
-   [Michael Clark workshop](https://m-clark.github.io/text-analysis-with-R/intro.html)

------------------------------------------------------------------------


## Bootstrapping

Imagine you had a sample of 6 people: Rachel, Monica, Phoebe, Joey, Chandler, and Ross. To bootstrap their heights, you would draw from this group many samples of 6 people *with replacement*, each time calculating the average height of the sample.

```{r, echo = F}
set.seed(112224)
friends = c("Rachel", "Monica", "Phoebe", "Joey", "Chandler", "Ross")
heights = c(65, 65, 68, 70, 72, 73)
names(heights) = friends
(sample1 = sample(friends, size = 6, replace = T)); mean(heights[sample1])
(sample1 = sample(friends, size = 6, replace = T)); mean(heights[sample1])
(sample1 = sample(friends, size = 6, replace = T)); mean(heights[sample1])
(sample1 = sample(friends, size = 6, replace = T)); mean(heights[sample1])
(sample1 = sample(friends, size = 6, replace = T)); mean(heights[sample1])
(sample1 = sample(friends, size = 6, replace = T)); mean(heights[sample1])
(sample1 = sample(friends, size = 6, replace = T)); mean(heights[sample1])
(sample1 = sample(friends, size = 6, replace = T)); mean(heights[sample1])
```

::: notes
```{r}
heights
```
:::

------------------------------------------------------------------------

```{r}
boot = 10000 # number of bootstraps
# make named vector (names not necessary)
heights = c("Rachel" = 65, "Monica" = 65, "Phoebe" = 68, 
            "Joey" = 70, "Chandler" = 72, "Ross" = 73)
heights

#a vector to store values
sample_means = numeric(length = boot)

for(i in 1:boot){ #loop through bootstraps
  # draw new sample with replacement
  this_sample = sample(heights, size = length(heights), replace = T)
  # store mean in empty vector
  sample_means[i] = mean(this_sample)
}

sample_means
```

------------------------------------------------------------------------

```{r, echo = F, message = F, fig.width = 10, fig.height=6, warning = F}
library(ggpubr)
mu = mean(heights)
sem = sd(heights)/sqrt(length(heights))
cv_t = qt(p = .975, df = length(heights)-1)

bootstrapped = data.frame(means = sample_means) %>%
  ggplot(aes(x = means)) + 
  geom_histogram(color = "white") +
  geom_density() +
  geom_vline(aes(xintercept = mean(sample_means), color = "mean"), size = 2) +
  geom_vline(aes(xintercept = median(sample_means), color = "median"), size = 2) +
  geom_vline(aes(xintercept = quantile(sample_means, probs = .025), color = "Lower 2.5%"), size = 2) +
    geom_vline(aes(xintercept = quantile(sample_means, probs = .975), color = "Upper 2.5%"), size = 2) +
  scale_x_continuous(limits = c(mu-3*sem, mu+3*sem))+
  ggtitle("Bootstrapped sampling distribution") +
  cowplot::theme_cowplot()


from_prob = data.frame(means = seq(from = min(sample_means), to = max(sample_means))) %>%
  ggplot(aes(x = means)) +
  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem)) + 
  geom_vline(aes(xintercept = mean(heights), color = "mean"), size = 2) +
  geom_vline(aes(xintercept = mean(heights), color = "median"), size = 2) +
  geom_vline(aes(xintercept = mu-cv_t*sem, color = "Lower 2.5%"), size = 2) +
  geom_vline(aes(xintercept = mu+cv_t*sem, color = "Upper 2.5%"), size = 2) +scale_x_continuous(limits = c(mu-3*sem, mu+3*sem))+  
  ggtitle("Theoretical sampling distribution") +
  cowplot::theme_cowplot()

ggarrange(bootstrapped, from_prob, ncol = 1)
```

------------------------------------------------------------------------

::::: columns
::: {.column width="50%"}
Hypothetical example:

A researcher examines the effect of caffeine on reaction times. Twenty-five participants had their reaction times measured before and after consuming caffeine. The units are in milliseconds, with baseline (pre-caffeine) reactions ranging roughly from 200-800ms.
:::

::: {.column width="50%"}
Code to simulate data

```{r}
# Set random seed
set.seed(112224)

# Generate skewed data using chi-square distributions
n <- 25
pre_caffeine <- rchisq(n, df=3) * 100 + 200
post_caffeine <- pre_caffeine - rchisq(n, df=2) * 20

# Create data frame
data <- data.frame(
  pre_caffeine = pre_caffeine,
  post_caffeine = post_caffeine,
  difference = pre_caffeine - post_caffeine
)
```
:::
:::::

------------------------------------------------------------------------

Assumptions of t-tests?

-   Independence

-   **Normality**

------------------------------------------------------------------------

::::: columns
::: {.column width="50%"}
```{r, echo = F, fig.height = 10}
data %>% 
  ggplot(aes(x = difference)) +
  geom_histogram(
    aes(y = ..density..),
    color = "white", 
    binwidth = 30
    ) +
  geom_density() +
  theme_minimal()
```
:::

::: {.column width="50%"}
Not only are these data skewed, but we would expect the population distribution (reaction times) to be skewed as well.

Furthermore, our sample size (25) is small enough for us to give pause before applying the CLT.
:::
:::::

------------------------------------------------------------------------

We can't reasonably meet the assumptions of a *t*-test, so we cannot use this test. Instead, we'll use bootstrapping.

```{r}
# how many simulations?
n_boots = 1000
# create an empty vector to hold results
boot_diff = numeric(length = 1000)
set.seed(112224) # set seed to ensure the random results are the same every time
for(i in 1:n_boots){
  # sample with replacement. new dataset is the same size as the original
  bootdata = data[sample(1:nrow(data), size = nrow(data), replace = T), ]
  # calculate mean in new dataset
  mean_diff = mean(bootdata$difference)
  # add to empty vector
  boot_diff[i] = mean_diff
}
head(boot_diff)
```

------------------------------------------------------------------------

```{r}
data.frame(boot_diff = boot_diff) %>% 
  ggplot(aes(x = boot_diff)) +
  geom_histogram(
    aes(y = ..density..),
    color = "white"
    ) +
  geom_density() +
  theme_minimal()
```


------------------------------------------------------------------------

::::: columns
::: {.column width="50%"}
What's the median bootstrapped difference?
  
```{r}
median(boot_diff)
```

What's the empirical 95% CI?


```{r}
quantile(boot_diff, probs = c(.025, .975))
```

Note: there is NO *p*-value for this test.
:::

::: {.column width="50%"}
How does this compare to the t-test?

```{r}
t.test(data$difference)
```
:::
:::::

------------------------------------------------------------------------

Bootstrapping can be used for any statistic you care about.

```{r}
#| code-fold: true
data %>% 
  pivot_longer(cols = contains("caff")) %>% 
  ggplot(aes(x = value, fill = name)) +
  geom_histogram(
    position = position_dodge(), 
    color = "white",
    binwidth = 100) +
  guides(fill = "none") +
  facet_wrap(~name) +
  theme_minimal()
```

Are the variances of these groups different?

------------------------------------------------------------------------

```{r}
n_boots = 1000
boot_var_diff  = numeric(length = 1000)
set.seed(112224)
for(i in 1:n_boots){
  bootdata = data[sample(1:nrow(data), size = nrow(data), replace = T), ]
  
  var_pre  = var(bootdata$pre_caffeine)
  var_post = var(bootdata$post_caffeine)

  boot_var_diff[i] = var_post - var_pre
}
head(boot_var_diff)
```

------------------------------------------------------------------------

```{r}
data.frame(boot_var_diff = boot_var_diff) %>% 
  ggplot(aes(x = boot_var_diff)) +
  geom_histogram(
    aes(y = ..density..),
    color = "white"
    ) +
  geom_density() +
  theme_minimal()
```

```{r}
quantile(boot_var_diff, probs = c(.025, .50, .975))
```

### Questions?



